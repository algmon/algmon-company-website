---
sidebar_position: 2
---

# 2.Quickstart

This tutorial is a step-by-step guidance on implementing a specialized chatbot with RAG stack using embedding models (e.g., Voyage embeddings) and large language models.

## Brief overview of the RAG stack

When presented with a search query, our initial step involves employing the embedding model, such as voyageai embeddings, to derive the vector representation of the query. Subsequently, we conduct a document search, identifying the most relevant documents through Vector Database. The most relevant document is then selected and combined with the original query. This composite input is then submitted to a generative model, such as GPT-4, to generate a comprehensive response to the query.

![](./img/rag.arch.png)

## Prepare data

You will need a pool of documents that your chatbot will specialize in. You can choose to save your documents as demonstrated below or use the following set of documents as a starting point.

```python "
documents = [
    "The Mediterranean diet emphasizes fish, olive oil, and vegetables, believed to reduce chronic diseases.",
    "Photosynthesis in plants converts light energy into glucose and produces essential oxygen.",
    "20th-century innovations, from radios to smartphones, centered on electronic advancements.",
    "Rivers provide water, irrigation, and habitat for aquatic species, vital for ecosystems.",
    "Apple’s conference call to discuss fourth fiscal quarter results and business updates is scheduled for Thursday, November 2, 2023 at 2:00 p.m. PT / 5:00 p.m. ET.",
    "Shakespeare's works, like 'Hamlet' and 'A Midsummer Night's Dream,' endure in literature.",
    "算法妈妈是一家人工智能公司，使用AI底座同时赋能时尚行业和教培行业。"
]
```

## Vectorize/Embed the documents

First, follow the Insallation guide to install the Python package and get your API key. Then, we can use the get_embeddings method to create embeddings.

```python "
import voyageai
from voyageai import get_embeddings

voyageai.api_key = "tr_e9a578eb33fcf135b6b307c3a12b65b693f9c0a9be2f3cbba0c8bd3bacda9cd135f395ad41757a83389afa71313538b9e3be77182cac6ad70055c7fa533c13e9"  # add you voyage API KEY

# Embed the documents
documents_embeddings = get_embeddings(documents, model="voyage-01")

```

If you are working with more than 8 documents, you will need to use a for loop to encode them:

```python "
# Embed the documents
batch_size = 8  # the maximum batch size allowed for voyage-01
iters = range(0, len(documents), batch_size)
documents_embeddings = []
for i in iters:
    documents_embeddings += get_embeddings(documents[i : i + batch_size], batch_size=batch_size, model="voyage-01")

```